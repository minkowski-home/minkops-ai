{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d03d098",
   "metadata": {},
   "source": [
    "## Quick Prototyping and Scratch Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3b84cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from langchain.chat_models import init_chat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17246946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a49a79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2312754c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_chat_model(\n",
    "    model='gpt-4o',\n",
    "    temperature=3,\n",
    "    api_key=OPENAI_API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07cf7cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import agents.general.imel.graph as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee6f7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def qualification_stage(: str) -> str:\n",
    "    response = model.chat([{\"role\": \"user\", \"content\": question}])\n",
    "    return response.content\n",
    "\n",
    "\n",
    "tools = []\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "model_with_tools = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3431a591",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import AnyMessage\n",
    "from typing_extensions import TypedDict, Annotated\n",
    "import operator\n",
    "\n",
    "class MessageState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]\n",
    "    llm_calls: int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04c6447",
   "metadata": {},
   "source": [
    "### Imel: Reads, analyzes, and responds to emails. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f0cb97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Literal, Any, Annotated\n",
    "\n",
    "# Define the structure for email classification\n",
    "class EmailClassification(TypedDict):\n",
    "    intent: Literal[\"question\", \"bug\", \"billing\", \"feature\", \"complex\"]\n",
    "    urgency: Literal[\"low\", \"medium\", \"high\", \"critical\"]\n",
    "    topic: str\n",
    "    summary: str\n",
    "\n",
    "class EmailAgentState(TypedDict):\n",
    "    # Raw email data\n",
    "    email_content: str \n",
    "    sender_email: str\n",
    "    email_id: str\n",
    "\n",
    "    # Classification result\n",
    "    classification: EmailClassification | None\n",
    "\n",
    "    # Raw search/API results\n",
    "    search_results: list[str] | None  # List of raw document chunks\n",
    "    customer_history: dict | None  # Raw customer data from CRM\n",
    "\n",
    "    # Generated content\n",
    "    draft_response: str | None\n",
    "    messages: Annotated[list[Any], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26e5bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import interrupt, Command, RetryPolicy\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.messages import HumanMessage\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-5-nano\")\n",
    "\n",
    "def read_email(state: EmailAgentState) -> dict[str, list[HumanMessage]]:\n",
    "    \"\"\"Extract and parse email content\"\"\"\n",
    "    # In production, this would connect to your email service\n",
    "    return {\n",
    "        \"messages\": [HumanMessage(content=f\"Processing email: {state['email_content']}\")]   # Return the update to the State (not the complete state)\n",
    "    }\n",
    "\n",
    "def classify_intent(state: EmailAgentState) -> Command[Literal[\"search_documentation\", \"human_review\", \"draft_response\", \"bug_tracking\"]]:\n",
    "    \"\"\"Use LLM to classify email intent and urgency, then route accordingly\"\"\"\n",
    "\n",
    "    # Create structured LLM that returns EmailClassification dict\n",
    "    structured_llm = llm.with_structured_output(EmailClassification)\n",
    "\n",
    "    # Format the prompt on-demand, not stored in state\n",
    "    classification_prompt = f\"\"\"\n",
    "    Analyze this customer email and classify it:\n",
    "\n",
    "    Email: {state['email_content']}\n",
    "    From: {state['sender_email']}\n",
    "\n",
    "    Provide classification including intent, urgency, topic, and summary.\n",
    "    \"\"\"     # Raw strings are wrapped in a HumanMessage() object before sending to LLM\n",
    "\n",
    "    # Get structured response directly as dict\n",
    "    classification = EmailClassification(structured_llm.invoke(classification_prompt))  # type: ignore\n",
    "\n",
    "    # Determine next node based on classification\n",
    "    if classification['intent'] == 'billing' or classification['urgency'] == 'critical':\n",
    "        goto = \"human_review\"\n",
    "    elif classification['intent'] in ['question', 'feature']:\n",
    "        goto = \"search_documentation\"\n",
    "    elif classification['intent'] == 'bug':\n",
    "        goto = \"bug_tracking\"\n",
    "    else:\n",
    "        goto = \"draft_response\"\n",
    "\n",
    "    # Store classification as a single dict in state\n",
    "    # Command can update state and specify next node within the same node's logic, unlike the Graph API where a separate conditional edge is needed\n",
    "    # The `update` parameter takes a dict of state updates - these are the modified keys and values to merge into the current state (this is not the full state)\n",
    "    # If a key (of the `update` dict) implements a reducer (like `Annotated[list[Any], operator.add]`), the update value will be merged using that reducer instead of replaced. \n",
    "    # There is no reducer with `classification`, so it will simply replace the previous value - but the remaining state keys will be preserved.\n",
    "    return Command(\n",
    "        update={\"classification\": classification},\n",
    "        goto=goto\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae8ad2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_documentation(state: EmailAgentState) -> Command[Literal[\"draft_response\"]]:\n",
    "    \"\"\"Search knowledge base for relevant information\"\"\"\n",
    "\n",
    "    # Build search query from classification\n",
    "    classification = state.get('classification', {})\n",
    "    query = f\"{classification.get('intent', '')} {classification.get('topic', '')}\"\n",
    "\n",
    "    try:\n",
    "        # Implement your search logic here\n",
    "        # Store raw search results, not formatted text\n",
    "        search_results = [\n",
    "            \"Reset password via Settings > Security > Change Password\",\n",
    "            \"Password must be at least 12 characters\",\n",
    "            \"Include uppercase, lowercase, numbers, and symbols\"\n",
    "        ]\n",
    "    except SearchAPIError as e:\n",
    "        # For recoverable search errors, store error and continue\n",
    "        search_results = [f\"Search temporarily unavailable: {str(e)}\"]\n",
    "\n",
    "    return Command(\n",
    "        update={\"search_results\": search_results},  # Store raw results or error\n",
    "        goto=\"draft_response\"\n",
    "    )\n",
    "\n",
    "def bug_tracking(state: EmailAgentState) -> Command[Literal[\"draft_response\"]]:\n",
    "    \"\"\"Create or update bug tracking ticket\"\"\"\n",
    "\n",
    "    # Create ticket in your bug tracking system\n",
    "    ticket_id = \"BUG-12345\"  # Would be created via API\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"search_results\": [f\"Bug ticket {ticket_id} created\"],\n",
    "            \"current_step\": \"bug_tracked\"\n",
    "        },\n",
    "        goto=\"draft_response\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be72ffdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-suite",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
